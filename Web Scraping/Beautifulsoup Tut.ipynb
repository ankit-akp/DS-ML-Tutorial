{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '<!DOCTYPE html>\\\n",
    "<html>\\\n",
    "<head>\\\n",
    "<title>Testing Web Page</title>\\\n",
    "</head>\\\n",
    "<body>\\\n",
    "<h1> Web Scraping </h1>\\\n",
    "<p id=\"first_para\">\\\n",
    "Let\\'s start learning\\\n",
    "<b>\\\n",
    "Web Scraping\\\n",
    "</b>\\\n",
    "</p>\\\n",
    "<p class=\"abc\" id=\"second_para\">\\\n",
    "You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a>\\\n",
    "</p>\\\n",
    "<p class=\"abc\">\\\n",
    "<a href=\"https://www.codingninjas.com/\">Coding Ninjas</a>\\\n",
    "</p>\\\n",
    "</body>\\\n",
    "</html>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "<!DOCTYPE html>\n",
      "<html><head><title>Testing Web Page</title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body></html>\n"
     ]
    }
   ],
   "source": [
    "# how to parse content\n",
    "\n",
    "# data=data=BeautifulSoup(content,parser)\n",
    "# content is of type string and parser is the name of parser\n",
    "\n",
    "data=BeautifulSoup(html,'html.parser')\n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Testing Web Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Web Scraping\n",
      "  </h1>\n",
      "  <p id=\"first_para\">\n",
      "   Let's start learning\n",
      "   <b>\n",
      "    Web Scraping\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"abc\" id=\"second_para\">\n",
      "   You have to read more about beautifulsoup\n",
      "   <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "    here\n",
      "   </a>\n",
      "  </p>\n",
      "  <p class=\"abc\">\n",
      "   <a href=\"https://www.codingninjas.com/\">\n",
      "    Coding Ninjas\n",
      "   </a>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Show data in formatted way\n",
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title>Testing Web Page</title></head>\n",
      "<title>Testing Web Page</title>\n",
      "<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get any element's first occurrence\n",
    "# data.elementName\n",
    "\n",
    "print(data.head)\n",
    "print(data.title)\n",
    "print(data.p)\n",
    "\n",
    "# If element is not present then it will not return anything\n",
    "# and there will be no error\n",
    "\n",
    "print(data.h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title\n",
      "Testing Web Page\n",
      "Testing Web Page\n",
      "{'id': 'first_para'}\n"
     ]
    }
   ],
   "source": [
    "# Some more attributes\n",
    "print(data.title.name) # Name of element\n",
    "print(data.title.string) # content of element\n",
    "print(data.head.string) # How?\n",
    "print(data.p.attrs) # To get attributes of element\n",
    "\n",
    "# data.element.name will be None for strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'first_para'}\n",
      "first_para\n",
      "first_para\n"
     ]
    }
   ],
   "source": [
    "# how to get value of attribute\n",
    "print(data.p.attrs)\n",
    "\n",
    "print(data.p.get('id'))\n",
    "print(data.p['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8855f14dc1de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \"\"\"tag[key] returns the value of the 'key' attribute for the Tag,\n\u001b[1;32m   1320\u001b[0m         and throws an exception if it's not there.\"\"\"\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "print(data.p['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.p.get('class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Web Page Web Scraping Let's start learningWeb ScrapingYou have to read more about beautifulsoup hereCoding Ninjas\n"
     ]
    }
   ],
   "source": [
    "# how to get all text\n",
    "\n",
    "print(data.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Web Page\n",
      "Testing Web Page\n"
     ]
    }
   ],
   "source": [
    "print(data.title.get_text())\n",
    "print(data.head.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>\n",
      "<class 'bs4.element.Tag'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# data.find() returns first occurence of element\n",
    "print(data.find('p'))\n",
    "print(type(data.find('p')))\n",
    "\n",
    "# If element is not present then it returns nothing\n",
    "print(data.find('h2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>\n",
      "<p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>\n",
      "<p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p>\n"
     ]
    }
   ],
   "source": [
    "# data.find_all() or element.find_all() finds all occurence of specific tag\n",
    "# we can pass string, list, True, Using id, Using class, Using CSS selector\n",
    "# in find_all() and find()\n",
    "\n",
    "# In find() we get only first occurence\n",
    "# In find_all() we get all occurences\n",
    "li=data.find_all('p')\n",
    "\n",
    "for i in li:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>, <p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>, <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a>, <p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p>, <a href=\"https://www.codingninjas.com/\">Coding Ninjas</a>]\n"
     ]
    }
   ],
   "source": [
    "print(data.find_all(['p','a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>\n"
     ]
    }
   ],
   "source": [
    "print(data.find(['p','a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<html><head><title>Testing Web Page</title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body></html>, <head><title>Testing Web Page</title></head>, <title>Testing Web Page</title>, <body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body>, <h1> Web Scraping </h1>, <p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>, <b>Web Scraping</b>, <p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>, <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a>, <p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p>, <a href=\"https://www.codingninjas.com/\">Coding Ninjas</a>]\n"
     ]
    }
   ],
   "source": [
    "# print all tags\n",
    "print(data.find_all(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>\n",
      "[<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>]\n"
     ]
    }
   ],
   "source": [
    "# find tag by id\n",
    "print(data.find(id='first_para'))\n",
    "\n",
    "print(data.find_all(id='first_para'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>\n",
      "[<p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>, <p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p>]\n",
      "[<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>, <p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>]\n"
     ]
    }
   ],
   "source": [
    "# Find tags by className\n",
    "print(data.find(class_='abc'))\n",
    "print(data.find_all(class_='abc'))\n",
    "print(data.find_all(id=True)) # List of element having id as attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>, <p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p>]\n",
      "[<p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>]\n",
      "[<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a>, <a href=\"https://www.codingninjas.com/\">Coding Ninjas</a>]\n"
     ]
    }
   ],
   "source": [
    "# Find elements by CSS Selector\n",
    "\n",
    "# Beautiful Soup provides the .select() method which is \n",
    "# used to run a CSS selector against a parsed document \n",
    "# and return all the matching elements. \n",
    "\n",
    "print(data.select('p.abc'))\n",
    "print(data.select('p.abc#second_para'))\n",
    "print(data.select('p a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Testing Web Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Web Scraping\n",
      "  </h1>\n",
      "  <p id=\"first_para\">\n",
      "   Let's start learning\n",
      "   <b>\n",
      "    Web Scraping\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"abc\" id=\"second_para\">\n",
      "   You have to read more about beautifulsoup\n",
      "   <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "    here\n",
      "   </a>\n",
      "  </p>\n",
      "  <p class=\"abc\">\n",
      "   <a href=\"https://www.codingninjas.com/\">\n",
      "    Coding Ninjas\n",
      "   </a>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Traversing parse tree\n",
    "\n",
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Testing Web Page</title>\n"
     ]
    }
   ],
   "source": [
    "# data.element1.element2.....\n",
    "print(data.head.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "Coding Ninjas\n",
      "[<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>, <p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>, <p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p>]\n"
     ]
    }
   ],
   "source": [
    "# data.element.string -> This is used when element has only one child\n",
    "# for multiple children it returns none\n",
    "li=data.select('p')\n",
    "for i in li:\n",
    "    print(i.string)\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's start learning\", 'Web Scraping']\n",
      "['You have to read more about beautifulsoup ', 'here']\n",
      "['Coding Ninjas']\n"
     ]
    }
   ],
   "source": [
    "# data.elemet.strings -> This works fine with multiple strings\n",
    "# To show result we need to wrap output of data.element.strings\n",
    "# into list()\n",
    "li=data.select('p')\n",
    "for i in li:\n",
    "    print(list(i.strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Let's start learning\", 'Web Scraping']\n",
      "['You have to read more about beautifulsoup', 'here']\n",
      "['Coding Ninjas']\n"
     ]
    }
   ],
   "source": [
    "# print strings with removed whitespaces\n",
    "# Removes extra space from start and end\n",
    "li=data.select('p')\n",
    "for i in li:\n",
    "    print(list(i.stripped_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[<head><title>Testing Web Page</title></head>, <body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body>]\n"
     ]
    }
   ],
   "source": [
    "# List of childrens\n",
    "li=data.html.contents\n",
    "print(len(li))\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<list_iterator object at 0x7f19aa5e6f90>\n",
      "<head><title>Testing Web Page</title></head>\n",
      "<body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body>\n"
     ]
    }
   ],
   "source": [
    "# data.element.children gives the iterator of children\n",
    "\n",
    "l=data.html.children\n",
    "print(l)\n",
    "\n",
    "for i in l:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head><title>Testing Web Page</title></head>\n",
      "<title>Testing Web Page</title>\n",
      "Testing Web Page\n",
      "<body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body>\n",
      "<h1> Web Scraping </h1>\n",
      " Web Scraping \n",
      "<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>\n",
      "Let's start learning\n",
      "<b>Web Scraping</b>\n",
      "Web Scraping\n",
      "<p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p>\n",
      "You have to read more about beautifulsoup \n",
      "<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a>\n",
      "here\n",
      "<p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p>\n",
      "<a href=\"https://www.codingninjas.com/\">Coding Ninjas</a>\n",
      "Coding Ninjas\n"
     ]
    }
   ],
   "source": [
    "# data.element.descendants returns everything below me\n",
    "\n",
    "l=data.html.descendants\n",
    "for i in l:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Testing Web Page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   Web Scraping\n",
      "  </h1>\n",
      "  <p id=\"first_para\">\n",
      "   Let's start learning\n",
      "   <b>\n",
      "    Web Scraping\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"abc\" id=\"second_para\">\n",
      "   You have to read more about beautifulsoup\n",
      "   <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "    here\n",
      "   </a>\n",
      "  </p>\n",
      "  <p class=\"abc\">\n",
      "   <a href=\"https://www.codingninjas.com/\">\n",
      "    Coding Ninjas\n",
      "   </a>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p id=\"first_para\">Let's start learning<b>Web Scraping</b></p>]\n",
      "---------------\n",
      "<body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body>\n",
      "---------------\n",
      "<body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body>\n",
      "<html><head><title>Testing Web Page</title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body></html>\n",
      "<!DOCTYPE html>\n",
      "<html><head><title>Testing Web Page</title></head><body><h1> Web Scraping </h1><p id=\"first_para\">Let's start learning<b>Web Scraping</b></p><p class=\"abc\" id=\"second_para\">You have to read more about beautifulsoup <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">here</a></p><p class=\"abc\"><a href=\"https://www.codingninjas.com/\">Coding Ninjas</a></p></body></html>\n"
     ]
    }
   ],
   "source": [
    "# .parent , .parents\n",
    "elm=data.select('p#first_para')\n",
    "print(elm)\n",
    "print('---------------')\n",
    "print(elm[0].parent)\n",
    "print('---------------')\n",
    "for i in elm[0].parents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .next_sibling and .previous_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Navigate Parse Tree\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is your Assignment\n",
      "  </h1>\n",
      "  <a href=\"https://www.google.com\">\n",
      "   This is a link that will take you to Google\n",
      "  </a>\n",
      "  <ul>\n",
      "   <li>\n",
      "    <p>\n",
      "     This question is given to test your knowledge of\n",
      "     <b>\n",
      "      Web Scraping\n",
      "     </b>\n",
      "    </p>\n",
      "    <p>\n",
      "     Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.\n",
      "    </p>\n",
      "   </li>\n",
      "   <li id=\"li2\">\n",
      "    This is an li tag given to you for scraping\n",
      "   </li>\n",
      "   <li>\n",
      "    This li tag gives you the various ways to get data from a website\n",
      "    <ol>\n",
      "     <li class=\"list_or\">\n",
      "      Using API of the website\n",
      "     </li>\n",
      "     <li>\n",
      "      Scrape data using BeautifulSoup\n",
      "     </li>\n",
      "     <li>\n",
      "      Scrape data using Selenium\n",
      "     </li>\n",
      "     <li>\n",
      "      Scrape data using Scrapy\n",
      "     </li>\n",
      "    </ol>\n",
      "   </li>\n",
      "   <li class=\"list_or\">\n",
      "    <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "     Clicking on this takes you to the documentation of BeautifulSoup\n",
      "    </a>\n",
      "    <a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">\n",
      "     Clicking on this takes you to the documentation of Selenium\n",
      "    </a>\n",
      "   </li>\n",
      "  </ul>\n",
      " </body>\n",
      "</html>\n",
      "<li>This li tag gives you the various ways to get data from a website<ol><li class=\"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li><li>Scrape data using Scrapy</li></ol></li>\n",
      "<li class=\"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">Clicking on this takes you to the documentation of BeautifulSoup</a><a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a></li>\n"
     ]
    }
   ],
   "source": [
    "# .next_siblings and .previous_siblings\n",
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data=BeautifulSoup(html,'html.parser')\n",
    "print(data.prettify())\n",
    "elm=data.select('#li2')[0]\n",
    "# print(elm.next_siblings)\n",
    "for i in elm.next_siblings:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicking on this takes you to the documentation of BeautifulSoup\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Navigate Parse Tree\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is your Assignment\n",
      "  </h1>\n",
      "  <a href=\"https://www.google.com\">\n",
      "   This is a link that will take you to Google\n",
      "  </a>\n",
      "  <ul>\n",
      "   <li>\n",
      "    <p>\n",
      "     This question is given to test your knowledge of\n",
      "     <b>\n",
      "      Web Scraping\n",
      "     </b>\n",
      "    </p>\n",
      "    <p>\n",
      "     Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.\n",
      "    </p>\n",
      "   </li>\n",
      "   <li id=\"li2\">\n",
      "    This is an li tag given to you for scraping\n",
      "   </li>\n",
      "   <li>\n",
      "    This li tag gives you the various ways to get data from a website\n",
      "    <ol>\n",
      "     <li class=\"list_or\">\n",
      "      Using API of the website\n",
      "     </li>\n",
      "     <li>\n",
      "      Scrape data using BeautifulSoup\n",
      "     </li>\n",
      "     <li>\n",
      "      Scrape data using Selenium\n",
      "     </li>\n",
      "     <li>\n",
      "      Scrape data using Scrapy\n",
      "     </li>\n",
      "    </ol>\n",
      "   </li>\n",
      "   <li class=\"list_or\">\n",
      "    <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
      "     Clicking on this takes you to the documentation of BeautifulSoup\n",
      "    </a>\n",
      "    <a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">\n",
      "     Clicking on this takes you to the documentation of Selenium\n",
      "    </a>\n",
      "   </li>\n",
      "  </ul>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# next_element and .previous_element\n",
    "html = '<!DOCTYPE html><html><head><title>Navigate Parse Tree</title></head>\\\n",
    "<body><h1>This is your Assignment</h1><a href = \"https://www.google.com\">This is a link that will take you to Google</a>\\\n",
    "<ul><li><p> This question is given to test your knowledge of <b>Web Scraping</b></p>\\\n",
    "<p>Web scraping is a term used to describe the use of a program or algorithm to extract and process large amounts of data from the web.</p></li>\\\n",
    "<li id = \"li2\">This is an li tag given to you for scraping</li>\\\n",
    "<li>This li tag gives you the various ways to get data from a website\\\n",
    "<ol><li class = \"list_or\">Using API of the website</li><li>Scrape data using BeautifulSoup</li><li>Scrape data using Selenium</li>\\\n",
    "<li>Scrape data using Scrapy</li></ol></li>\\\n",
    "<li class = \"list_or\"><a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\\\n",
    "Clicking on this takes you to the documentation of BeautifulSoup</a>\\\n",
    "<a href=\"https://selenium-python.readthedocs.io/\" id=\"anchor\">Clicking on this takes you to the documentation of Selenium</a>\\\n",
    "</li></ul></body></html>'\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "data=BeautifulSoup(html,'html.parser')\n",
    "\n",
    "elm=data.find_all('a')[1]\n",
    "print(elm.next_element)\n",
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .next_elements and .previous_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<header>\n",
      " <title>\n",
      "  The World Wide Web project\n",
      " </title>\n",
      " <nextid n=\"55\"/>\n",
      "</header>\n",
      "<body>\n",
      " <h1>\n",
      "  World Wide Web\n",
      " </h1>\n",
      " The WorldWideWeb (W3) is a wide-area\n",
      " <a href=\"WhatIs.html\" name=\"0\">\n",
      "  hypermedia\n",
      " </a>\n",
      " information retrieval\n",
      "initiative aiming to give universal\n",
      "access to a large universe of documents.\n",
      " <p>\n",
      "  Everything there is online about\n",
      "W3 is linked directly or indirectly\n",
      "to this document, including an\n",
      "  <a href=\"Summary.html\" name=\"24\">\n",
      "   executive\n",
      "summary\n",
      "  </a>\n",
      "  of the project,\n",
      "  <a href=\"Administration/Mailing/Overview.html\" name=\"29\">\n",
      "   Mailing lists\n",
      "  </a>\n",
      "  ,\n",
      "  <a href=\"Policy.html\" name=\"30\">\n",
      "   Policy\n",
      "  </a>\n",
      "  , November's\n",
      "  <a href=\"News/9211.html\" name=\"34\">\n",
      "   W3  news\n",
      "  </a>\n",
      "  ,\n",
      "  <a href=\"FAQ/List.html\" name=\"41\">\n",
      "   Frequently Asked Questions\n",
      "  </a>\n",
      "  .\n",
      "  <dl>\n",
      "   <dt>\n",
      "    <a href=\"../DataSources/Top.html\" name=\"44\">\n",
      "     What's out there?\n",
      "    </a>\n",
      "    <dd>\n",
      "     Pointers to the\n",
      "world's online information,\n",
      "     <a href=\"../DataSources/bySubject/Overview.html\" name=\"45\">\n",
      "      subjects\n",
      "     </a>\n",
      "     ,\n",
      "     <a href=\"../DataSources/WWW/Servers.html\" name=\"z54\">\n",
      "      W3 servers\n",
      "     </a>\n",
      "     , etc.\n",
      "     <dt>\n",
      "      <a href=\"Help.html\" name=\"46\">\n",
      "       Help\n",
      "      </a>\n",
      "      <dd>\n",
      "       on the browser you are using\n",
      "       <dt>\n",
      "        <a href=\"Status.html\" name=\"13\">\n",
      "         Software Products\n",
      "        </a>\n",
      "        <dd>\n",
      "         A list of W3 project\n",
      "components and their current state.\n",
      "(e.g.\n",
      "         <a href=\"LineMode/Browser.html\" name=\"27\">\n",
      "          Line Mode\n",
      "         </a>\n",
      "         ,X11\n",
      "         <a href=\"Status.html#35\" name=\"35\">\n",
      "          Viola\n",
      "         </a>\n",
      "         ,\n",
      "         <a href=\"NeXT/WorldWideWeb.html\" name=\"26\">\n",
      "          NeXTStep\n",
      "         </a>\n",
      "         ,\n",
      "         <a href=\"Daemon/Overview.html\" name=\"25\">\n",
      "          Servers\n",
      "         </a>\n",
      "         ,\n",
      "         <a href=\"Tools/Overview.html\" name=\"51\">\n",
      "          Tools\n",
      "         </a>\n",
      "         ,\n",
      "         <a href=\"MailRobot/Overview.html\" name=\"53\">\n",
      "          Mail robot\n",
      "         </a>\n",
      "         ,\n",
      "         <a href=\"Status.html#57\" name=\"52\">\n",
      "          Library\n",
      "         </a>\n",
      "         )\n",
      "         <dt>\n",
      "          <a href=\"Technical.html\" name=\"47\">\n",
      "           Technical\n",
      "          </a>\n",
      "          <dd>\n",
      "           Details of protocols, formats,\n",
      "program internals etc\n",
      "           <dt>\n",
      "            <a href=\"Bibliography.html\" name=\"40\">\n",
      "             Bibliography\n",
      "            </a>\n",
      "            <dd>\n",
      "             Paper documentation\n",
      "on  W3 and references.\n",
      "             <dt>\n",
      "              <a href=\"People.html\" name=\"14\">\n",
      "               People\n",
      "              </a>\n",
      "              <dd>\n",
      "               A list of some people involved\n",
      "in the project.\n",
      "               <dt>\n",
      "                <a href=\"History.html\" name=\"15\">\n",
      "                 History\n",
      "                </a>\n",
      "                <dd>\n",
      "                 A summary of the history\n",
      "of the project.\n",
      "                 <dt>\n",
      "                  <a href=\"Helping.html\" name=\"37\">\n",
      "                   How can I help\n",
      "                  </a>\n",
      "                  ?\n",
      "                  <dd>\n",
      "                   If you would like\n",
      "to support the web..\n",
      "                   <dt>\n",
      "                    <a href=\"../README.html\" name=\"48\">\n",
      "                     Getting code\n",
      "                    </a>\n",
      "                    <dd>\n",
      "                     Getting the code by\n",
      "                     <a href=\"LineMode/Defaults/Distribution.html\" name=\"49\">\n",
      "                      anonymous FTP\n",
      "                     </a>\n",
      "                     , etc.\n",
      "                    </dd>\n",
      "                   </dt>\n",
      "                  </dd>\n",
      "                 </dt>\n",
      "                </dd>\n",
      "               </dt>\n",
      "              </dd>\n",
      "             </dt>\n",
      "            </dd>\n",
      "           </dt>\n",
      "          </dd>\n",
      "         </dt>\n",
      "        </dd>\n",
      "       </dt>\n",
      "      </dd>\n",
      "     </dt>\n",
      "    </dd>\n",
      "   </dt>\n",
      "  </dl>\n",
      " </p>\n",
      "</body>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get html using get request\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res=req.get('http://info.cern.ch/hypertext/WWW/TheProject.html')\n",
    "html_data=res.text\n",
    "data=BeautifulSoup(html_data,'html.parser')\n",
    "print(data.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://books.toscrape.com/catalogue/page-1.html\n",
      "http://books.toscrape.com/catalogue/page-2.html\n",
      "http://books.toscrape.com/catalogue/page-3.html\n",
      "http://books.toscrape.com/catalogue/page-4.html\n",
      "http://books.toscrape.com/catalogue/page-5.html\n",
      "http://books.toscrape.com/catalogue/page-6.html\n",
      "http://books.toscrape.com/catalogue/page-7.html\n",
      "http://books.toscrape.com/catalogue/page-8.html\n",
      "http://books.toscrape.com/catalogue/page-9.html\n",
      "http://books.toscrape.com/catalogue/page-10.html\n",
      "http://books.toscrape.com/catalogue/page-11.html\n",
      "http://books.toscrape.com/catalogue/page-12.html\n",
      "http://books.toscrape.com/catalogue/page-13.html\n",
      "http://books.toscrape.com/catalogue/page-14.html\n",
      "http://books.toscrape.com/catalogue/page-15.html\n",
      "http://books.toscrape.com/catalogue/page-16.html\n",
      "http://books.toscrape.com/catalogue/page-17.html\n",
      "http://books.toscrape.com/catalogue/page-18.html\n",
      "http://books.toscrape.com/catalogue/page-19.html\n",
      "http://books.toscrape.com/catalogue/page-20.html\n",
      "http://books.toscrape.com/catalogue/page-21.html\n",
      "http://books.toscrape.com/catalogue/page-22.html\n",
      "http://books.toscrape.com/catalogue/page-23.html\n",
      "http://books.toscrape.com/catalogue/page-24.html\n",
      "http://books.toscrape.com/catalogue/page-25.html\n",
      "http://books.toscrape.com/catalogue/page-26.html\n",
      "http://books.toscrape.com/catalogue/page-27.html\n",
      "http://books.toscrape.com/catalogue/page-28.html\n",
      "http://books.toscrape.com/catalogue/page-29.html\n",
      "http://books.toscrape.com/catalogue/page-30.html\n",
      "http://books.toscrape.com/catalogue/page-31.html\n",
      "http://books.toscrape.com/catalogue/page-32.html\n",
      "http://books.toscrape.com/catalogue/page-33.html\n",
      "http://books.toscrape.com/catalogue/page-34.html\n",
      "http://books.toscrape.com/catalogue/page-35.html\n",
      "http://books.toscrape.com/catalogue/page-36.html\n",
      "http://books.toscrape.com/catalogue/page-37.html\n",
      "http://books.toscrape.com/catalogue/page-38.html\n",
      "http://books.toscrape.com/catalogue/page-39.html\n",
      "http://books.toscrape.com/catalogue/page-40.html\n",
      "http://books.toscrape.com/catalogue/page-41.html\n",
      "http://books.toscrape.com/catalogue/page-42.html\n",
      "http://books.toscrape.com/catalogue/page-43.html\n",
      "http://books.toscrape.com/catalogue/page-44.html\n",
      "http://books.toscrape.com/catalogue/page-45.html\n",
      "http://books.toscrape.com/catalogue/page-46.html\n",
      "http://books.toscrape.com/catalogue/page-47.html\n",
      "http://books.toscrape.com/catalogue/page-48.html\n",
      "http://books.toscrape.com/catalogue/page-49.html\n",
      "http://books.toscrape.com/catalogue/page-50.html\n"
     ]
    }
   ],
   "source": [
    "# This is code to get all page URL\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base='http://books.toscrape.com/catalogue/'\n",
    "nxt='page-1.html'\n",
    "res=req.get(base+nxt)\n",
    "\n",
    "# data=BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "urls=[]\n",
    "\n",
    "while res.status_code==200:\n",
    "    current=base+nxt\n",
    "    print(current)\n",
    "    urls.append(current)\n",
    "    data=BeautifulSoup(res.text,'html.parser')\n",
    "    if data.find(class_='next') is None:\n",
    "        break\n",
    "    nxt=data.find(class_='next').a.get('href')\n",
    "    res=req.get(base+nxt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<article class=\"product_pod\">\n",
      "<div class=\"image_container\">\n",
      "<a href=\"catalogue/a-light-in-the-attic_1000/index.html\"><img alt=\"A Light in the Attic\" class=\"thumbnail\" src=\"media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg\"/></a>\n",
      "</div>\n",
      "<p class=\"star-rating Three\">\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "<i class=\"icon-star\"></i>\n",
      "</p>\n",
      "<h3><a href=\"catalogue/a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>\n",
      "<div class=\"product_price\">\n",
      "<p class=\"price_color\">Â£51.77</p>\n",
      "<p class=\"instock availability\">\n",
      "<i class=\"icon-ok\"></i>\n",
      "    \n",
      "        In stock\n",
      "    \n",
      "</p>\n",
      "<form>\n",
      "<button class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\" type=\"submit\">Add to basket</button>\n",
      "</form>\n",
      "</div>\n",
      "</article>\n"
     ]
    }
   ],
   "source": [
    "# Save details of all the books in csv file\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "res=req.get('http://books.toscrape.com/')\n",
    "data=BeautifulSoup(res.text,'html.parser')\n",
    "b1=data.find(class_='product_pod')\n",
    "print(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n"
     ]
    }
   ],
   "source": [
    "base_url='http://books.toscrape.com/'\n",
    "b1_url=base_url+data.h3.a['href']\n",
    "print(b1_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic\n"
     ]
    }
   ],
   "source": [
    "res=req.get(b1_url)\n",
    "data=BeautifulSoup(res.text,'html.parser')\n",
    "title=data.h1.string\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â£51.77\n"
     ]
    }
   ],
   "source": [
    "price=data.find(class_='price_color').string\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stock (22 available)\n"
     ]
    }
   ],
   "source": [
    "qty=data.find(class_='instock availability').contents\n",
    "qty=qty[-1].strip()\n",
    "print(qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for regular expression\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "qty=int(re.search('\\d+',qty).group())\n",
    "print(qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.77\n"
     ]
    }
   ],
   "source": [
    "price=float(re.search('[\\d.]+',price).group())\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\n",
      "A Light in the Attic\n",
      "51.77\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(b1_url)\n",
    "print(title)\n",
    "print(price)\n",
    "print(qty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Title                                               Link  \\\n",
      "0  A Light in the Attic  http://books.toscrape.com/catalogue/a-light-in...   \n",
      "1  A Light in the Attic  http://books.toscrape.com/catalogue/a-light-in...   \n",
      "\n",
      "   Price  Quantity In Stock  \n",
      "0  51.77                 22  \n",
      "1  51.77                 22  \n"
     ]
    }
   ],
   "source": [
    "book_details=[]\n",
    "book_details.append([title,b1_url,price,qty])\n",
    "book_details.append([title,b1_url,price,qty])\n",
    "\n",
    "df=pd.DataFrame(book_details,columns=['Title','Link','Price','Quantity In Stock'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make csv file from dataframe\n",
    "df.to_csv('books.csv',index=False) \n",
    "# index=False removes first index column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Details\n",
    "Find and print the details of all books which are present on first 2 pages of this website.  \n",
    "All details include - Title of the book, book page url, Price (in float, without any currency or extra symbol), and quantity in stock (in integer). Save all the details in a dataframe and print in the required format.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html 51.77 22\n",
      "Tipping the Velvet http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html 53.74 20\n",
      "Soumission http://books.toscrape.com/catalogue/soumission_998/index.html 50.1 20\n",
      "Sharp Objects http://books.toscrape.com/catalogue/sharp-objects_997/index.html 47.82 20\n",
      "Sapiens: A Brief History of Humankind http://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html 54.23 20\n",
      "The Requiem Red http://books.toscrape.com/catalogue/the-requiem-red_995/index.html 22.65 19\n",
      "The Dirty Little Secrets of Getting Your Dream Job http://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html 33.34 19\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull http://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html 17.93 19\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics http://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html 22.6 19\n",
      "The Black Maria http://books.toscrape.com/catalogue/the-black-maria_991/index.html 52.15 19\n",
      "Starving Hearts (Triangular Trade Trilogy, #1) http://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html 13.99 19\n",
      "Shakespeare's Sonnets http://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html 20.66 19\n",
      "Set Me Free http://books.toscrape.com/catalogue/set-me-free_988/index.html 17.46 19\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1) http://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html 52.29 19\n",
      "Rip it Up and Start Again http://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html 35.02 19\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991 http://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html 57.25 19\n",
      "Olio http://books.toscrape.com/catalogue/olio_984/index.html 23.88 19\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849 http://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html 37.59 19\n",
      "Libertarianism for Beginners http://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html 51.33 19\n",
      "It's Only the Himalayas http://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html 45.17 19\n",
      "In Her Wake http://books.toscrape.com/catalogue/in-her-wake_980/index.html 12.84 19\n",
      "How Music Works http://books.toscrape.com/catalogue/how-music-works_979/index.html 37.32 19\n",
      "Foolproof Preserving: A Guide to Small Batch Jams, Jellies, Pickles, Condiments, and More: A Foolproof Guide to Making Small Batch Jams, Jellies, Pickles, Condiments, and More http://books.toscrape.com/catalogue/foolproof-preserving-a-guide-to-small-batch-jams-jellies-pickles-condiments-and-more-a-foolproof-guide-to-making-small-batch-jams-jellies-pickles-condiments-and-more_978/index.html 30.52 19\n",
      "Chase Me (Paris Nights #2) http://books.toscrape.com/catalogue/chase-me-paris-nights-2_977/index.html 25.27 19\n",
      "Black Dust http://books.toscrape.com/catalogue/black-dust_976/index.html 34.53 19\n",
      "Birdsong: A Story in Pictures http://books.toscrape.com/catalogue/birdsong-a-story-in-pictures_975/index.html 54.64 19\n",
      "America's Cradle of Quarterbacks: Western Pennsylvania's Football Factory from Johnny Unitas to Joe Montana http://books.toscrape.com/catalogue/americas-cradle-of-quarterbacks-western-pennsylvanias-football-factory-from-johnny-unitas-to-joe-montana_974/index.html 22.5 19\n",
      "Aladdin and His Wonderful Lamp http://books.toscrape.com/catalogue/aladdin-and-his-wonderful-lamp_973/index.html 53.13 19\n",
      "Worlds Elsewhere: Journeys Around Shakespeareâs Globe http://books.toscrape.com/catalogue/worlds-elsewhere-journeys-around-shakespeares-globe_972/index.html 40.3 18\n",
      "Wall and Piece http://books.toscrape.com/catalogue/wall-and-piece_971/index.html 44.18 18\n",
      "The Four Agreements: A Practical Guide to Personal Freedom http://books.toscrape.com/catalogue/the-four-agreements-a-practical-guide-to-personal-freedom_970/index.html 17.66 18\n",
      "The Five Love Languages: How to Express Heartfelt Commitment to Your Mate http://books.toscrape.com/catalogue/the-five-love-languages-how-to-express-heartfelt-commitment-to-your-mate_969/index.html 31.05 18\n",
      "The Elephant Tree http://books.toscrape.com/catalogue/the-elephant-tree_968/index.html 23.82 18\n",
      "The Bear and the Piano http://books.toscrape.com/catalogue/the-bear-and-the-piano_967/index.html 36.89 18\n",
      "Sophie's World http://books.toscrape.com/catalogue/sophies-world_966/index.html 15.94 18\n",
      "Penny Maybe http://books.toscrape.com/catalogue/penny-maybe_965/index.html 33.29 18\n",
      "Maude (1883-1993):She Grew Up with the country http://books.toscrape.com/catalogue/maude-1883-1993she-grew-up-with-the-country_964/index.html 18.02 18\n",
      "In a Dark, Dark Wood http://books.toscrape.com/catalogue/in-a-dark-dark-wood_963/index.html 19.63 18\n",
      "Behind Closed Doors http://books.toscrape.com/catalogue/behind-closed-doors_962/index.html 52.22 18\n",
      "You can't bury them all: Poems http://books.toscrape.com/catalogue/you-cant-bury-them-all-poems_961/index.html 33.63 17\n"
     ]
    }
   ],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "base_url='http://books.toscrape.com/catalogue/'\n",
    "\n",
    "def addBookDetails(url,book_details):\n",
    "    res=req.get(url)\n",
    "    data=BeautifulSoup(res.text,'html.parser')\n",
    "    title=data.h1.string\n",
    "    price=data.find(class_='price_color').string\n",
    "    price=float(re.search('[\\d.]+',price).group())\n",
    "    qty=data.find(class_='instock availability').contents\n",
    "    qty=qty[-1].strip()\n",
    "    qty=int(re.search('\\d+',qty).group())\n",
    "    book_details.append([title,url,price,qty])\n",
    "    \n",
    "\n",
    "allPages = ['http://books.toscrape.com/catalogue/page-1.html',\n",
    "            'http://books.toscrape.com/catalogue/page-2.html']\n",
    "\n",
    "column_names = ['Title', 'Link', 'Price', 'Quantity in Stock']\n",
    "\n",
    "book_details=[]\n",
    "\n",
    "for i in allPages:\n",
    "    res=req.get(i)\n",
    "    data=BeautifulSoup(res.text,'html.parser')\n",
    "    li=data.find_all(class_='product_pod')\n",
    "#     print(li)\n",
    "    for i in li:\n",
    "        book_url=base_url+i.h3.a['href']\n",
    "#         print(book_url)\n",
    "        addBookDetails(book_url,book_details)\n",
    "\n",
    "df=pd.DataFrame(book_details,columns=column_names)\n",
    "# print(df)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    print(df['Title'][i],df['Link'][i],df['Price'][i],df['Quantity in Stock'][i])\n",
    "df.to_csv('book_detailsAssignment.csv',index=False) # To create csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
